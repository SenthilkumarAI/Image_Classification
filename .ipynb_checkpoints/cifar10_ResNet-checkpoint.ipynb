{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9456dfdb-f0b5-482d-86c6-4c4afcbe158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59a12d4e-cf67-4fed-963a-a44ab2b1b6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: .\\cifar.tgz\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"http://pjreddie.com/media/files/cifar.tgz\"\n",
    "download_url(dataset_url,'.')\n",
    "with tarfile.open('./cifar.tgz','r') as tar:\n",
    "    tar.extractall(path='./data1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "38ef3a65-f63c-4c9a-8a3d-40dd573540a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['labels.txt', 'test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Look into the data directory\n",
    "data_dir = './data1/cifar'\n",
    "print(os.listdir(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d583316c-3149-4515-b091-b54a429f735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(data_dir, 'labels.txt'), \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "labels = data.split('\\n')\n",
    "if '' in labels:\n",
    "    labels.remove('')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "524653d3-481a-4005-8101-6903727d7777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_folder = [sub_dir for sub_dir in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir,sub_dir))]\n",
    "train_test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d864a9e-4ae2-44de-a8e6-f5b82ca4ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in train_test_folder:\n",
    "    for cls_name in labels:\n",
    "        if not os.path.exists(os.path.join(data_dir, each, cls_name)):\n",
    "            os.mkdir(os.path.join(data_dir, each, cls_name))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2a61b998-5330-4dd4-ab21-383cbb477cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "533cfdf2-cbfa-48ef-906a-779f041250fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in train_test_folder:\n",
    "    for src_path in glob.glob(os.path.join(data_dir, each, \"*.png\")):\n",
    "        dest_path = os.path.join(data_dir, each, (os.path.basename(src_path).split(\"_\")[1].split('.')[0]))\n",
    "        shutil.move(src_path,dest_path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f1b89956-dd13-46fd-805d-5deee801b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3d816d4-3bef-4b1b-a891-a39d3ae2314a",
   "metadata": {},
   "source": [
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "       \n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "mean, std = get_mean_std(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2eccc6c5-d218-4218-84cf-c153ef55eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = ((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a2a22-6e15-4b37-8c8c-b2673101431f",
   "metadata": {},
   "source": [
    "Data Augmentation should be done only on the Traning images and not on the validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7ce7ff82-6265-4915-bcc7-67998e272f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats, inplace=True) # modify the existing tensors without making copy\n",
    "])\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "20543a08-ca44-428d-b4e0-dbda40da98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "train_dataset1 = ImageFolder(data_dir + \"/train\")\n",
    "valid_dataset1 = ImageFolder(data_dir + \"/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5cc754a-893c-487f-8942-fd45372397a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "17a3397f-3122-41a3-ae47-10bb5a54e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Senthilkumar\\AppData\\Local\\Temp\\ipykernel_2104\\2495341476.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for img_path in tqdm_notebook(glob.glob(os.path.join(data_dir, 'train',\"*.png\"))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8005e528f24912807b84ee9c1acef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_sum_r, mean_sum_g, mean_sum_b = 0,0,0\n",
    "std_sum_r, std_sum_g, std_sum_b = 0,0,0\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "data_dir = './data/cifar'\n",
    "all_mean_rgb= [0, 0, 0]\n",
    "all_std_rgb = [0, 0, 0]\n",
    "for img_path in tqdm(glob.glob(os.path.join(data_dir, 'train',\"*.png\"))):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    img_np = np.asarray(img)\n",
    "    mean_rgb = img_np.mean(axis=(0,1))\n",
    "    std_rgb = img_np.std(axis=(0,1))\n",
    "    all_mean_rgb = all_mean_rgb + mean_rgb\n",
    "    all_std_rgb = all_std_rgb + std_rgb\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3b1a463-6dba-46a8-bc6b-c9b51b53115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12237004, 0.12006874, 0.11119666])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mean_rgb/(50000*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b076336-65e9-4dff-b339-4776c6460604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05035307, 0.04963421, 0.05001971])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_std_rgb/(50000*32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b38e3bd-d8d7-4360-b0c3-8a07e023d37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2578076.99182133, 2541271.57525891, 2561009.13732902])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_std_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cdc527a4-f59e-4b03-88f9-7b98e6d90cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "afc7c566-0801-427c-8353-03ffe42ca719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_cifar10(Dataset):\n",
    "    def __int__(self):\n",
    "        self.img_dir = r\"./data/cifar/train\"\n",
    "\n",
    "    def __len__(self):\n",
    "        classes = [each.split('_')[1].split('.')[0] for each in os.listdir(self.img_dir)]\n",
    "        cls_dict = {}\n",
    "        for cls in set(classes):\n",
    "            cls_len = len([each for each in classes if cls==each])\n",
    "            cls_dict[cls]=cls_len\n",
    "        return cls_dict\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "166f3ab3-0321-48dd-bc57-2fee9da30a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Custom_cifar10 at 0x1c3debd8340>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Custom_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e0b1446f-c33d-4df5-87e5-9c2e89810c3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Custom_cifar10' object has no attribute 'img_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCustom_cifar10\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[119], line 6\u001b[0m, in \u001b[0;36mCustom_cifar10.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     classes \u001b[38;5;241m=\u001b[39m [each\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_dir\u001b[49m)]\n\u001b[0;32m      7\u001b[0m     cls_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(classes):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Custom_cifar10' object has no attribute 'img_dir'"
     ]
    }
   ],
   "source": [
    "len(Custom_cifar10())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1babbc9-783d-41c7-b72a-eba99301d195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77622b72-19d8-4528-9f64-c304d0913ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1e16003-5c79-4969-98d6-ed6093ea347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[[1,1,1],[1,1,1],[1,1,1],[1,1,1]],[[2,2,2],[2,2,2],[2,2,2],[2,2,2]],[[3,3,3],[3,3,3],[3,3,3],[3,3,3]],[[4,4,4],[4,4,4],[4,4,4],[4,4,4]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611b4048-407a-4536-b7d3-946b3bb90e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "299f29a8-12ed-484d-87dc-b78bee6f05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5, 2.5, 2.5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.mean(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87058e3e-a3f0-43dd-8675-ffe008da0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa9ea65e-3ad3-40e8-b08a-db11a517f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(arr)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96638b65-82d9-401c-9ff1-d70410a01f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_float = tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41b1d7f3-491f-4a61-9bf4-472dcb1c2e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 2.5000, 2.5000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float.mean(dim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47e1ce7b-c95e-4077-a8d7-3fc8edefc68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float[:,:,0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13425810-b6d6-426b-ab78-77f8b1a44655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76479618-b3cf-49db-a332-38028303e246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
